{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "STAT4984_FinalProject.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "278ebebd7e76475aa8fd76f5ffc7f120": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4e5e55ae5c5c49e7b012bf1835292195",
              "IPY_MODEL_512146a4d9d04c3b8b530854dc8948e7",
              "IPY_MODEL_dd33d3fb73514a7ebb962f494cd21812"
            ],
            "layout": "IPY_MODEL_c164a7ac84f54e56a84a52d626966ccc"
          }
        },
        "4e5e55ae5c5c49e7b012bf1835292195": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5f103ae9a4548eda81c050f388c5772",
            "placeholder": "​",
            "style": "IPY_MODEL_3412ceb07154409baa846bfdd8c6d6d9",
            "value": ""
          }
        },
        "512146a4d9d04c3b8b530854dc8948e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8d2aa85b0fd48a1b31b685fc9a42885",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_647817f9013f4610ad749d1efe760117",
            "value": 170498071
          }
        },
        "dd33d3fb73514a7ebb962f494cd21812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77df8af920f0481dbf5ddf1b68053ca5",
            "placeholder": "​",
            "style": "IPY_MODEL_517631a60e97431aa7bd820665242e45",
            "value": " 170499072/? [00:02&lt;00:00, 59844760.46it/s]"
          }
        },
        "c164a7ac84f54e56a84a52d626966ccc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5f103ae9a4548eda81c050f388c5772": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3412ceb07154409baa846bfdd8c6d6d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8d2aa85b0fd48a1b31b685fc9a42885": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "647817f9013f4610ad749d1efe760117": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77df8af920f0481dbf5ddf1b68053ca5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "517631a60e97431aa7bd820665242e45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "STAT4984 Final Project\n",
        "\n",
        "Aditya Mallapragada"
      ],
      "metadata": {
        "id": "PEp-n_vH5qCR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CtUI0rbDprXd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms as tforms\n",
        "from torchvision import datasets as dsets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as functional\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "LkN7b5evp-Y7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = torchvision.datasets.CIFAR10('./data', train=True, download=True,transform=tforms.Compose([tforms.ToTensor()]))\n",
        "test = torchvision.datasets.CIFAR10('./data', train=False, download=True,transform=tforms.Compose([tforms.ToTensor()]))\n",
        "training_dataset = torch.utils.data.DataLoader(train, batch_size=64, shuffle=True)\n",
        "testing_dataset = torch.utils.data.DataLoader(test, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "278ebebd7e76475aa8fd76f5ffc7f120",
            "4e5e55ae5c5c49e7b012bf1835292195",
            "512146a4d9d04c3b8b530854dc8948e7",
            "dd33d3fb73514a7ebb962f494cd21812",
            "c164a7ac84f54e56a84a52d626966ccc",
            "f5f103ae9a4548eda81c050f388c5772",
            "3412ceb07154409baa846bfdd8c6d6d9",
            "e8d2aa85b0fd48a1b31b685fc9a42885",
            "647817f9013f4610ad749d1efe760117",
            "77df8af920f0481dbf5ddf1b68053ca5",
            "517631a60e97431aa7bd820665242e45"
          ]
        },
        "id": "laSMFwKNMbp5",
        "outputId": "ae35fab8-9423-428b-8f1c-23b8937bcffd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "278ebebd7e76475aa8fd76f5ffc7f120"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "J6IXxur1oP62"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 1: Basic CNN"
      ],
      "metadata": {
        "id": "MoDCTfzRK0r2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvolutionalNeuralNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ConvolutionalNeuralNet, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=2, stride=2)\n",
        "    self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=2, stride=2)  \n",
        "    self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=2, stride=1)  \n",
        "    self.fc1 = nn.Linear(128, 64)\n",
        "    self.fc2 = nn.Linear(64, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "      y = self.conv1(x)\n",
        "      y = functional.relu(y)\n",
        "      y = self.pool1(y)\n",
        "      y = self.conv2(y)\n",
        "      y = functional.relu(y)\n",
        "      y = self.pool2(y)\n",
        "      y = self.conv3(y)\n",
        "      y = torch.flatten(y, 1)\n",
        "      y = self.fc1(y)\n",
        "      y = functional.relu(y)\n",
        "      y = self.fc2(y)\n",
        "      return y"
      ],
      "metadata": {
        "id": "s5vLT4QsSJVk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_net = ConvolutionalNeuralNet().to(device)\n",
        "print(conv_net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_Zov0xSmyPd",
        "outputId": "477324c6-bfcd-496a-be15-6c09b476fd3a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ConvolutionalNeuralNet(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(2, 2), stride=(2, 2))\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2))\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(2, 2), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(conv_net.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "ewFGSa6fGMNd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = [num for num in range(40)]\n",
        "accuracy_list = []\n",
        "for epoch in num_epochs: \n",
        "    classified_right = 0.0\n",
        "    classified_total = 0.0\n",
        "    training_index = 0.0\n",
        "    loss_epoch = 0.0\n",
        "    accuracy_epoch = 0.0\n",
        "    loss_current = 0.0\n",
        "    for train_data in training_dataset:  \n",
        "        images, labels = train_data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device) \n",
        "        conv_net.zero_grad()  \n",
        "        output = conv_net(images)  \n",
        "        loss = loss_function(output, labels)  \n",
        "        loss.backward()  \n",
        "        optimizer.step()  \n",
        "        enum = enumerate(output)\n",
        "        for index, a in enum:\n",
        "          classified_total += 1.0\n",
        "          if torch.argmax(a) == labels[index]:\n",
        "              classified_right += 1.0\n",
        "        loss_item = loss.item()\n",
        "        loss_current += loss_item\n",
        "        training_index += 1.0\n",
        "    loss_epoch = loss_current / training_index\n",
        "    accuracy_epoch = classified_right / classified_total\n",
        "    print(\"Epoch \" + str(epoch) + \" Training Loss: \" + str(loss_epoch) + \",     Training Accuracy: \" + str(accuracy_epoch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asMMgCyUGShO",
        "outputId": "01e66086-a9fc-414d-a47f-0684b8621f39"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Training Loss: 1.821129041559556,     Training Accuracy: 0.32082\n",
            "Epoch 1 Training Loss: 1.5444364384617038,     Training Accuracy: 0.42632\n",
            "Epoch 2 Training Loss: 1.434954092935528,     Training Accuracy: 0.47148\n",
            "Epoch 3 Training Loss: 1.3591079506117973,     Training Accuracy: 0.5013\n",
            "Epoch 4 Training Loss: 1.3066981302960146,     Training Accuracy: 0.52616\n",
            "Epoch 5 Training Loss: 1.261992835404013,     Training Accuracy: 0.54172\n",
            "Epoch 6 Training Loss: 1.2283891319009044,     Training Accuracy: 0.55746\n",
            "Epoch 7 Training Loss: 1.194274018868766,     Training Accuracy: 0.56788\n",
            "Epoch 8 Training Loss: 1.1638764771049286,     Training Accuracy: 0.58206\n",
            "Epoch 9 Training Loss: 1.1427543538305767,     Training Accuracy: 0.58764\n",
            "Epoch 10 Training Loss: 1.125495948068931,     Training Accuracy: 0.59746\n",
            "Epoch 11 Training Loss: 1.1053772767638916,     Training Accuracy: 0.60156\n",
            "Epoch 12 Training Loss: 1.0903448773467022,     Training Accuracy: 0.60998\n",
            "Epoch 13 Training Loss: 1.0762031885516612,     Training Accuracy: 0.6155\n",
            "Epoch 14 Training Loss: 1.0640094620949776,     Training Accuracy: 0.61876\n",
            "Epoch 15 Training Loss: 1.0467616629112713,     Training Accuracy: 0.62502\n",
            "Epoch 16 Training Loss: 1.038560440625681,     Training Accuracy: 0.62822\n",
            "Epoch 17 Training Loss: 1.02306949139556,     Training Accuracy: 0.6344\n",
            "Epoch 18 Training Loss: 1.0156503730570263,     Training Accuracy: 0.63516\n",
            "Epoch 19 Training Loss: 1.0089553186045888,     Training Accuracy: 0.6391\n",
            "Epoch 20 Training Loss: 0.9993032815358828,     Training Accuracy: 0.64266\n",
            "Epoch 21 Training Loss: 0.9867944584020873,     Training Accuracy: 0.64752\n",
            "Epoch 22 Training Loss: 0.9768318241971838,     Training Accuracy: 0.65326\n",
            "Epoch 23 Training Loss: 0.9709405393704124,     Training Accuracy: 0.6546\n",
            "Epoch 24 Training Loss: 0.9602764663488969,     Training Accuracy: 0.65676\n",
            "Epoch 25 Training Loss: 0.9551499136116194,     Training Accuracy: 0.65894\n",
            "Epoch 26 Training Loss: 0.9509297515577673,     Training Accuracy: 0.65984\n",
            "Epoch 27 Training Loss: 0.942650432476912,     Training Accuracy: 0.66474\n",
            "Epoch 28 Training Loss: 0.9331392963676501,     Training Accuracy: 0.66632\n",
            "Epoch 29 Training Loss: 0.9303349691736119,     Training Accuracy: 0.66874\n",
            "Epoch 30 Training Loss: 0.925789137782953,     Training Accuracy: 0.66988\n",
            "Epoch 31 Training Loss: 0.9174593652758147,     Training Accuracy: 0.67486\n",
            "Epoch 32 Training Loss: 0.9153925152995702,     Training Accuracy: 0.67312\n",
            "Epoch 33 Training Loss: 0.9030465599521041,     Training Accuracy: 0.67678\n",
            "Epoch 34 Training Loss: 0.899425475265059,     Training Accuracy: 0.6782\n",
            "Epoch 35 Training Loss: 0.895693414808844,     Training Accuracy: 0.68042\n",
            "Epoch 36 Training Loss: 0.8889379162922539,     Training Accuracy: 0.6827\n",
            "Epoch 37 Training Loss: 0.8822504163855482,     Training Accuracy: 0.6859\n",
            "Epoch 38 Training Loss: 0.8801088156297688,     Training Accuracy: 0.6872\n",
            "Epoch 39 Training Loss: 0.8742728000864044,     Training Accuracy: 0.68814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_correct = 0.0\n",
        "test_total = 0.0\n",
        "with torch.no_grad():\n",
        "    for test_data in testing_dataset:\n",
        "        images, labels = test_data\n",
        "        images = images.to(device)  \n",
        "        labels = labels.to(device)\n",
        "        output = conv_net(images)\n",
        "        enum = enumerate(output)\n",
        "        for index, a in enum:\n",
        "          test_total += 1.0\n",
        "          if torch.argmax(a) == labels[index]:\n",
        "            test_correct += 1.0\n",
        "accuracy_epoch = test_correct / test_total\n",
        "print(\"Testing Loss: \" + str(loss_epoch) + \",     Testing Accuracy: \" + str(accuracy_epoch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DI69XuWhyIAa",
        "outputId": "168429e8-817d-43cd-ec93-c14cb9025e11"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Loss: 0.8742728000864044,     Testing Accuracy: 0.6072\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 2: More Linear Layers, More Parameters and Higher Learning Rate"
      ],
      "metadata": {
        "id": "wU4I2ZoLHE6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvolutionalNeuralNet2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ConvolutionalNeuralNet2, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=512, kernel_size=2, stride=2)\n",
        "    self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.conv2 = nn.Conv2d(in_channels=512, out_channels=128, kernel_size=2, stride=2)  \n",
        "    self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.conv3 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=2, stride=2)   \n",
        "    self.fc1 = nn.Linear(128, 128)\n",
        "    self.fc2 = nn.Linear(128, 64)\n",
        "    self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "      y = self.conv1(x)\n",
        "      y = functional.relu(y)\n",
        "      y = self.pool1(y)\n",
        "      y = self.conv2(y)\n",
        "      y = functional.relu(y)\n",
        "      y = self.pool2(y)\n",
        "      y = self.conv3(y)\n",
        "      y = torch.flatten(y, 1)\n",
        "      y = self.fc1(y)\n",
        "      y = functional.relu(y)\n",
        "      y = self.fc2(y)\n",
        "      y = functional.relu(y)\n",
        "      y = self.fc3(y)\n",
        "      return y"
      ],
      "metadata": {
        "id": "A16ZtQA5Gej0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_net_2 = ConvolutionalNeuralNet2().to(device)\n",
        "print(conv_net_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yI6r6w1HGvMP",
        "outputId": "bcec8ff3-c475-4a05-8da1-3e50076a1522"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ConvolutionalNeuralNet2(\n",
            "  (conv1): Conv2d(3, 512, kernel_size=(2, 2), stride=(2, 2))\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(512, 128, kernel_size=(2, 2), stride=(2, 2))\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
            "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(conv_net_2.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "JrcqWcxGGxBa"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = [num for num in range(40)]\n",
        "accuracy_list = []\n",
        "for epoch in num_epochs: \n",
        "    classified_right = 0.0\n",
        "    classified_total = 0.0\n",
        "    training_index = 0.0\n",
        "    loss_epoch = 0.0\n",
        "    accuracy_epoch = 0.0\n",
        "    loss_current = 0.0\n",
        "    for train_data in training_dataset:  \n",
        "        images, labels = train_data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device) \n",
        "        conv_net_2.zero_grad()  \n",
        "        output = conv_net_2(images)  \n",
        "        loss = loss_function(output, labels)  \n",
        "        loss.backward()  \n",
        "        optimizer.step()  \n",
        "        enum = enumerate(output)\n",
        "        for index, a in enum:\n",
        "          classified_total += 1.0\n",
        "          if torch.argmax(a) == labels[index]:\n",
        "              classified_right += 1.0\n",
        "        loss_item = loss.item()\n",
        "        loss_current += loss_item\n",
        "        training_index += 1.0\n",
        "    loss_epoch = loss_current / training_index\n",
        "    accuracy_epoch = classified_right / classified_total\n",
        "    print(\"Epoch \" + str(epoch) + \" Training Loss: \" + str(loss_epoch) + \",     Training Accuracy: \" + str(accuracy_epoch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfsrUb-vG2W0",
        "outputId": "59bfc04e-ff89-4d33-9740-acc252deccd5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Training Loss: 1.875935906796809,     Training Accuracy: 0.28642\n",
            "Epoch 1 Training Loss: 1.706293952129686,     Training Accuracy: 0.36282\n",
            "Epoch 2 Training Loss: 1.646045821706962,     Training Accuracy: 0.395\n",
            "Epoch 3 Training Loss: 1.6017529121445269,     Training Accuracy: 0.41368\n",
            "Epoch 4 Training Loss: 1.5766871039519834,     Training Accuracy: 0.41948\n",
            "Epoch 5 Training Loss: 1.561179314580415,     Training Accuracy: 0.4299\n",
            "Epoch 6 Training Loss: 1.5491063828053682,     Training Accuracy: 0.43266\n",
            "Epoch 7 Training Loss: 1.5437832528063098,     Training Accuracy: 0.43398\n",
            "Epoch 8 Training Loss: 1.5331460144513709,     Training Accuracy: 0.44036\n",
            "Epoch 9 Training Loss: 1.5304102246718638,     Training Accuracy: 0.44272\n",
            "Epoch 10 Training Loss: 1.519857694883176,     Training Accuracy: 0.447\n",
            "Epoch 11 Training Loss: 1.5159868180294476,     Training Accuracy: 0.44494\n",
            "Epoch 12 Training Loss: 1.5147155029389558,     Training Accuracy: 0.44784\n",
            "Epoch 13 Training Loss: 1.5048345743542741,     Training Accuracy: 0.45286\n",
            "Epoch 14 Training Loss: 1.5025210764706898,     Training Accuracy: 0.4537\n",
            "Epoch 15 Training Loss: 1.5013772386419193,     Training Accuracy: 0.45512\n",
            "Epoch 16 Training Loss: 1.4982758540936443,     Training Accuracy: 0.45706\n",
            "Epoch 17 Training Loss: 1.490875900325263,     Training Accuracy: 0.4578\n",
            "Epoch 18 Training Loss: 1.4875366846313867,     Training Accuracy: 0.45962\n",
            "Epoch 19 Training Loss: 1.4782612822244845,     Training Accuracy: 0.46382\n",
            "Epoch 20 Training Loss: 1.4777127725388997,     Training Accuracy: 0.46422\n",
            "Epoch 21 Training Loss: 1.4735294234417284,     Training Accuracy: 0.46608\n",
            "Epoch 22 Training Loss: 1.4754628850066143,     Training Accuracy: 0.46808\n",
            "Epoch 23 Training Loss: 1.4681686900765694,     Training Accuracy: 0.46908\n",
            "Epoch 24 Training Loss: 1.4644864126849357,     Training Accuracy: 0.4716\n",
            "Epoch 25 Training Loss: 1.458438993872279,     Training Accuracy: 0.47102\n",
            "Epoch 26 Training Loss: 1.4634155321609028,     Training Accuracy: 0.4721\n",
            "Epoch 27 Training Loss: 1.4549205899238586,     Training Accuracy: 0.47554\n",
            "Epoch 28 Training Loss: 1.4538935834489515,     Training Accuracy: 0.47518\n",
            "Epoch 29 Training Loss: 1.4527725258751598,     Training Accuracy: 0.47874\n",
            "Epoch 30 Training Loss: 1.4572786515021263,     Training Accuracy: 0.47396\n",
            "Epoch 31 Training Loss: 1.4458847498649832,     Training Accuracy: 0.47932\n",
            "Epoch 32 Training Loss: 1.4520254551297258,     Training Accuracy: 0.47736\n",
            "Epoch 33 Training Loss: 1.45013725178321,     Training Accuracy: 0.47758\n",
            "Epoch 34 Training Loss: 1.4469741712445798,     Training Accuracy: 0.47948\n",
            "Epoch 35 Training Loss: 1.437022296364045,     Training Accuracy: 0.48216\n",
            "Epoch 36 Training Loss: 1.440940084969601,     Training Accuracy: 0.48114\n",
            "Epoch 37 Training Loss: 1.4403634485991106,     Training Accuracy: 0.48092\n",
            "Epoch 38 Training Loss: 1.4398009130716933,     Training Accuracy: 0.48164\n",
            "Epoch 39 Training Loss: 1.4357892634618619,     Training Accuracy: 0.48426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_correct = 0.0\n",
        "test_total = 0.0\n",
        "with torch.no_grad():\n",
        "    for test_data in testing_dataset:\n",
        "        images, labels = test_data\n",
        "        images = images.to(device)  \n",
        "        labels = labels.to(device)\n",
        "        output = conv_net_2(images)\n",
        "        enum = enumerate(output)\n",
        "        for index, a in enum:\n",
        "          test_total += 1.0\n",
        "          if torch.argmax(a) == labels[index]:\n",
        "            test_correct += 1.0\n",
        "accuracy_epoch = test_correct / test_total\n",
        "print(\"Testing Loss: \" + str(loss_epoch) + \",     Testing Accuracy: \" + str(accuracy_epoch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0_iAwEFHPYK",
        "outputId": "9c1420b1-3dce-4b4c-ed14-ef3e94d995c4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Loss: 1.4357892634618619,     Testing Accuracy: 0.457\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 3: VGG Two Conv and Pool Block CNN and SGD Optimizer "
      ],
      "metadata": {
        "id": "FMFk97dBffOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvolutionalNeuralNet3(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ConvolutionalNeuralNet3, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=2, stride=2)\n",
        "    self.conv2 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=2, stride=2)  \n",
        "    self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.conv3 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=2, stride=2)  \n",
        "    self.conv4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=2, stride=2)  \n",
        "    self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.fc1 = nn.Linear(1024, 512)\n",
        "    self.fc2 = nn.Linear(512, 128)\n",
        "    self.fc3 = nn.Linear(128, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "      y = self.conv1(x)\n",
        "      y = functional.relu(y)\n",
        "      y = self.conv2(y)\n",
        "      y = functional.relu(y)\n",
        "      y = self.pool1(y)\n",
        "      y = self.conv3(x)\n",
        "      y = functional.relu(y)\n",
        "      y = self.conv4(y)\n",
        "      y = functional.relu(y)\n",
        "      y = self.pool2(y)\n",
        "      y = torch.flatten(y, 1)\n",
        "      y = self.fc1(y)\n",
        "      y = functional.relu(y)\n",
        "      y = self.fc2(y)\n",
        "      y = functional.relu(y)\n",
        "      y = self.fc3(y)\n",
        "      return y"
      ],
      "metadata": {
        "id": "SfCo1OOJQr26"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_net_3 = ConvolutionalNeuralNet3().to(device)\n",
        "print(conv_net_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_p5nvYtQzcA",
        "outputId": "35defc24-b80f-4f6a-a01e-aeeee0cdefca"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ConvolutionalNeuralNet3(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(2, 2), stride=(2, 2))\n",
            "  (conv2): Conv2d(16, 16, kernel_size=(2, 2), stride=(2, 2))\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(3, 64, kernel_size=(2, 2), stride=(2, 2))\n",
            "  (conv4): Conv2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
            "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(conv_net_3.parameters(), lr=0.01, momentum=0.9)"
      ],
      "metadata": {
        "id": "BWrqblWfQ2FL"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = [num for num in range(40)]\n",
        "accuracy_list = []\n",
        "for epoch in num_epochs: \n",
        "    classified_right = 0.0\n",
        "    classified_total = 0.0\n",
        "    training_index = 0.0\n",
        "    loss_epoch = 0.0\n",
        "    accuracy_epoch = 0.0\n",
        "    loss_current = 0.0\n",
        "    for train_data in training_dataset:  \n",
        "        images, labels = train_data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device) \n",
        "        conv_net_3.zero_grad()  \n",
        "        output = conv_net_3(images)  \n",
        "        loss = loss_function(output, labels)  \n",
        "        loss.backward()  \n",
        "        optimizer.step()  \n",
        "        enum = enumerate(output)\n",
        "        for index, a in enum:\n",
        "          classified_total += 1.0\n",
        "          if torch.argmax(a) == labels[index]:\n",
        "              classified_right += 1.0\n",
        "        loss_item = loss.item()\n",
        "        loss_current += loss_item\n",
        "        training_index += 1.0\n",
        "    loss_epoch = loss_current / training_index\n",
        "    accuracy_epoch = classified_right / classified_total\n",
        "    print(\"Epoch \" + str(epoch) + \" Training Loss: \" + str(loss_epoch) + \",     Training Accuracy: \" + str(accuracy_epoch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJzYgKheQ2-j",
        "outputId": "e2a65796-7087-41ad-92b3-19b1c218e885"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Training Loss: 2.037738325803176,     Training Accuracy: 0.23916\n",
            "Epoch 1 Training Loss: 1.507803651377978,     Training Accuracy: 0.45268\n",
            "Epoch 2 Training Loss: 1.3478377946197528,     Training Accuracy: 0.51262\n",
            "Epoch 3 Training Loss: 1.217900978101184,     Training Accuracy: 0.56292\n",
            "Epoch 4 Training Loss: 1.0998022647007653,     Training Accuracy: 0.6065\n",
            "Epoch 5 Training Loss: 1.0014992519412809,     Training Accuracy: 0.64202\n",
            "Epoch 6 Training Loss: 0.9188111889392824,     Training Accuracy: 0.6737\n",
            "Epoch 7 Training Loss: 0.8342466010614429,     Training Accuracy: 0.70358\n",
            "Epoch 8 Training Loss: 0.7488265068406035,     Training Accuracy: 0.73672\n",
            "Epoch 9 Training Loss: 0.6666494397937185,     Training Accuracy: 0.76516\n",
            "Epoch 10 Training Loss: 0.5823528167155697,     Training Accuracy: 0.7955\n",
            "Epoch 11 Training Loss: 0.4951778141891255,     Training Accuracy: 0.82548\n",
            "Epoch 12 Training Loss: 0.4219711245325825,     Training Accuracy: 0.85052\n",
            "Epoch 13 Training Loss: 0.3486707601743891,     Training Accuracy: 0.87654\n",
            "Epoch 14 Training Loss: 0.2838446235908267,     Training Accuracy: 0.89952\n",
            "Epoch 15 Training Loss: 0.2331358633430489,     Training Accuracy: 0.91672\n",
            "Epoch 16 Training Loss: 0.192378202303196,     Training Accuracy: 0.9313\n",
            "Epoch 17 Training Loss: 0.16876404663867048,     Training Accuracy: 0.93906\n",
            "Epoch 18 Training Loss: 0.14712851380695924,     Training Accuracy: 0.94846\n",
            "Epoch 19 Training Loss: 0.12431471212112043,     Training Accuracy: 0.95666\n",
            "Epoch 20 Training Loss: 0.11511969967218845,     Training Accuracy: 0.95892\n",
            "Epoch 21 Training Loss: 0.09769107367786224,     Training Accuracy: 0.9658\n",
            "Epoch 22 Training Loss: 0.08974174664193846,     Training Accuracy: 0.96846\n",
            "Epoch 23 Training Loss: 0.07947593889094394,     Training Accuracy: 0.97304\n",
            "Epoch 24 Training Loss: 0.06748645801556862,     Training Accuracy: 0.97762\n",
            "Epoch 25 Training Loss: 0.0541550459937476,     Training Accuracy: 0.98136\n",
            "Epoch 26 Training Loss: 0.050892523864892736,     Training Accuracy: 0.98268\n",
            "Epoch 27 Training Loss: 0.05602391707666857,     Training Accuracy: 0.98098\n",
            "Epoch 28 Training Loss: 0.0642664002321894,     Training Accuracy: 0.97838\n",
            "Epoch 29 Training Loss: 0.05206281155088197,     Training Accuracy: 0.98232\n",
            "Epoch 30 Training Loss: 0.050160237990306035,     Training Accuracy: 0.983\n",
            "Epoch 31 Training Loss: 0.02899320230475696,     Training Accuracy: 0.99078\n",
            "Epoch 32 Training Loss: 0.021967263316803806,     Training Accuracy: 0.99264\n",
            "Epoch 33 Training Loss: 0.06234070177093539,     Training Accuracy: 0.97926\n",
            "Epoch 34 Training Loss: 0.048840810341583066,     Training Accuracy: 0.98326\n",
            "Epoch 35 Training Loss: 0.04091627089373107,     Training Accuracy: 0.9865\n",
            "Epoch 36 Training Loss: 0.031633776820772695,     Training Accuracy: 0.98992\n",
            "Epoch 37 Training Loss: 0.026067775038867126,     Training Accuracy: 0.99146\n",
            "Epoch 38 Training Loss: 0.014186579169869973,     Training Accuracy: 0.99584\n",
            "Epoch 39 Training Loss: 0.005684422323955474,     Training Accuracy: 0.99834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_correct = 0.0\n",
        "test_total = 0.0\n",
        "with torch.no_grad():\n",
        "    for test_data in testing_dataset:\n",
        "        images, labels = test_data\n",
        "        images = images.to(device)  \n",
        "        labels = labels.to(device)\n",
        "        output = conv_net_3(images)\n",
        "        enum = enumerate(output)\n",
        "        for index, a in enum:\n",
        "          test_total += 1.0\n",
        "          if torch.argmax(a) == labels[index]:\n",
        "            test_correct += 1.0\n",
        "accuracy_epoch = test_correct / test_total\n",
        "print(\"Testing Loss: \" + str(loss_epoch) + \",     Testing Accuracy: \" + str(accuracy_epoch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXtEuo5DRRWz",
        "outputId": "6600138e-4648-44d6-c603-f5228b682691"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Loss: 0.005684422323955474,     Testing Accuracy: 0.6458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 4: VGG Three Conv and Pool Block CNN, Lower Learning Rate, and Batch Normalization"
      ],
      "metadata": {
        "id": "UP9H_I9ohpVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvolutionalNeuralNet4(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ConvolutionalNeuralNet4, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=2, stride=2)\n",
        "    self.conv2 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=2, stride=2)  \n",
        "    self.batch1 = nn.BatchNorm2d(16)\n",
        "    self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.conv3 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=2, stride=2)  \n",
        "    self.conv4 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=2, stride=2)  \n",
        "    self.batch2 = nn.BatchNorm2d(32)\n",
        "    self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.conv5 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=2, stride=2)\n",
        "    self.conv6 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=2, stride=2)  \n",
        "    self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.fc1 = nn.Linear(1024, 256)\n",
        "    self.fc2 = nn.Linear(256, 128)\n",
        "    self.fc3 = nn.Linear(128, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "      y = self.conv1(x)\n",
        "      y = functional.relu(y)\n",
        "      y = self.conv2(y)\n",
        "      y = functional.relu(y)\n",
        "      y = self.batch1(y)\n",
        "      y = self.pool1(y)\n",
        "      y = self.conv3(x)\n",
        "      y = functional.relu(y)\n",
        "      y = self.conv4(y)\n",
        "      y = functional.relu(y)\n",
        "      y = self.batch2(y)\n",
        "      y = self.pool2(y)\n",
        "      y = self.conv5(x)\n",
        "      y = functional.relu(y)\n",
        "      y = self.conv6(y)\n",
        "      y = functional.relu(y)\n",
        "      y = self.pool3(y)\n",
        "      y = torch.flatten(y, 1)\n",
        "      y = self.fc1(y)\n",
        "      y = functional.relu(y)\n",
        "      y = self.fc2(y)\n",
        "      y = functional.relu(y)\n",
        "      y = self.fc3(y)\n",
        "      return y"
      ],
      "metadata": {
        "id": "ru02XvdFgRf6"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_net_4 = ConvolutionalNeuralNet4().to(device)\n",
        "print(conv_net_4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSRjThHDgxt4",
        "outputId": "05794ef0-8687-4685-d958-64fd0f2f6918"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ConvolutionalNeuralNet4(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(2, 2), stride=(2, 2))\n",
            "  (conv2): Conv2d(16, 16, kernel_size=(2, 2), stride=(2, 2))\n",
            "  (batch1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(3, 32, kernel_size=(2, 2), stride=(2, 2))\n",
            "  (conv4): Conv2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
            "  (batch2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv5): Conv2d(3, 64, kernel_size=(2, 2), stride=(2, 2))\n",
            "  (conv6): Conv2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
            "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(conv_net_4.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "qdocA7--g1OJ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = [num for num in range(40)]\n",
        "accuracy_list = []\n",
        "for epoch in num_epochs: \n",
        "    classified_right = 0.0\n",
        "    classified_total = 0.0\n",
        "    training_index = 0.0\n",
        "    loss_epoch = 0.0\n",
        "    accuracy_epoch = 0.0\n",
        "    loss_current = 0.0\n",
        "    for train_data in training_dataset:  \n",
        "        images, labels = train_data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device) \n",
        "        conv_net_4.zero_grad()  \n",
        "        output = conv_net_4(images)  \n",
        "        loss = loss_function(output, labels)  \n",
        "        loss.backward()  \n",
        "        optimizer.step()  \n",
        "        enum = enumerate(output)\n",
        "        for index, a in enum:\n",
        "          classified_total += 1.0\n",
        "          if torch.argmax(a) == labels[index]:\n",
        "              classified_right += 1.0\n",
        "        loss_item = loss.item()\n",
        "        loss_current += loss_item\n",
        "        training_index += 1.0\n",
        "    loss_epoch = loss_current / training_index\n",
        "    accuracy_epoch = classified_right / classified_total\n",
        "    print(\"Epoch \" + str(epoch) + \" Training Loss: \" + str(loss_epoch) + \",     Training Accuracy: \" + str(accuracy_epoch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypGdc93_g5r3",
        "outputId": "045205d3-da36-4624-9cee-ca59c291b5e1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Training Loss: 2.296011539371422,     Training Accuracy: 0.13926\n",
            "Epoch 1 Training Loss: 2.231026102514828,     Training Accuracy: 0.18222\n",
            "Epoch 2 Training Loss: 2.0537724789146266,     Training Accuracy: 0.247\n",
            "Epoch 3 Training Loss: 1.9829933192114086,     Training Accuracy: 0.271\n",
            "Epoch 4 Training Loss: 1.8981528169358783,     Training Accuracy: 0.31022\n",
            "Epoch 5 Training Loss: 1.7762265857833122,     Training Accuracy: 0.35434\n",
            "Epoch 6 Training Loss: 1.6747304945040846,     Training Accuracy: 0.39352\n",
            "Epoch 7 Training Loss: 1.5931231765186085,     Training Accuracy: 0.42402\n",
            "Epoch 8 Training Loss: 1.5342843974642741,     Training Accuracy: 0.44582\n",
            "Epoch 9 Training Loss: 1.4850228500488165,     Training Accuracy: 0.46296\n",
            "Epoch 10 Training Loss: 1.4456998545800328,     Training Accuracy: 0.47798\n",
            "Epoch 11 Training Loss: 1.4125991831045321,     Training Accuracy: 0.49152\n",
            "Epoch 12 Training Loss: 1.3813722975113814,     Training Accuracy: 0.50374\n",
            "Epoch 13 Training Loss: 1.3500290312578,     Training Accuracy: 0.5157\n",
            "Epoch 14 Training Loss: 1.325303973291841,     Training Accuracy: 0.52628\n",
            "Epoch 15 Training Loss: 1.2986112912292676,     Training Accuracy: 0.53576\n",
            "Epoch 16 Training Loss: 1.2772623885927907,     Training Accuracy: 0.54458\n",
            "Epoch 17 Training Loss: 1.2561293193293959,     Training Accuracy: 0.5534\n",
            "Epoch 18 Training Loss: 1.23461555710534,     Training Accuracy: 0.5604\n",
            "Epoch 19 Training Loss: 1.2120578869834275,     Training Accuracy: 0.56832\n",
            "Epoch 20 Training Loss: 1.1896630338085887,     Training Accuracy: 0.57564\n",
            "Epoch 21 Training Loss: 1.1715992897215401,     Training Accuracy: 0.58264\n",
            "Epoch 22 Training Loss: 1.1530929722292038,     Training Accuracy: 0.58822\n",
            "Epoch 23 Training Loss: 1.1333447235929386,     Training Accuracy: 0.59716\n",
            "Epoch 24 Training Loss: 1.109587532708712,     Training Accuracy: 0.60738\n",
            "Epoch 25 Training Loss: 1.0931387321113626,     Training Accuracy: 0.61224\n",
            "Epoch 26 Training Loss: 1.072573814550629,     Training Accuracy: 0.621\n",
            "Epoch 27 Training Loss: 1.0555651245824516,     Training Accuracy: 0.62546\n",
            "Epoch 28 Training Loss: 1.0383004456987162,     Training Accuracy: 0.63182\n",
            "Epoch 29 Training Loss: 1.017241528272019,     Training Accuracy: 0.64038\n",
            "Epoch 30 Training Loss: 0.9985953794263512,     Training Accuracy: 0.64604\n",
            "Epoch 31 Training Loss: 0.9841555436248974,     Training Accuracy: 0.65268\n",
            "Epoch 32 Training Loss: 0.962589650888882,     Training Accuracy: 0.66012\n",
            "Epoch 33 Training Loss: 0.949436769765966,     Training Accuracy: 0.66562\n",
            "Epoch 34 Training Loss: 0.9274832956168962,     Training Accuracy: 0.67274\n",
            "Epoch 35 Training Loss: 0.9085683555096922,     Training Accuracy: 0.67912\n",
            "Epoch 36 Training Loss: 0.8953041535661653,     Training Accuracy: 0.6822\n",
            "Epoch 37 Training Loss: 0.8776710711781631,     Training Accuracy: 0.68956\n",
            "Epoch 38 Training Loss: 0.8590788760453539,     Training Accuracy: 0.69722\n",
            "Epoch 39 Training Loss: 0.8403591756777995,     Training Accuracy: 0.70344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_correct = 0.0\n",
        "test_total = 0.0\n",
        "with torch.no_grad():\n",
        "    for test_data in testing_dataset:\n",
        "        images, labels = test_data\n",
        "        images = images.to(device)  \n",
        "        labels = labels.to(device)\n",
        "        output = conv_net_4(images)\n",
        "        enum = enumerate(output)\n",
        "        for index, a in enum:\n",
        "          test_total += 1.0\n",
        "          if torch.argmax(a) == labels[index]:\n",
        "            test_correct += 1.0\n",
        "accuracy_epoch = test_correct / test_total\n",
        "print(\"Testing Loss: \" + str(loss_epoch) + \",     Testing Accuracy: \" + str(accuracy_epoch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgWO-Feug7PR",
        "outputId": "4d621f3f-a328-46e5-f7b8-77266bd74c65"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Loss: 0.8403591756777995,     Testing Accuracy: 0.6101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 5: VGG Three Conv and Pool Blocks and Dropout Regularization"
      ],
      "metadata": {
        "id": "Ft9aGQ6vmcGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvolutionalNeuralNet5(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ConvolutionalNeuralNet5, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=2, stride=2)\n",
        "    self.conv2 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=2, stride=2)  \n",
        "    self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.conv3 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=2, stride=2)  \n",
        "    self.conv4 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=2, stride=2)  \n",
        "    self.drop1 = nn.Dropout(0.3)\n",
        "    self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.conv5 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=2, stride=2)\n",
        "    self.conv6 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=2, stride=2)  \n",
        "    self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.drop2 = nn.Dropout(0.3)\n",
        "    self.fc1 = nn.Linear(1024, 256)\n",
        "    self.fc2 = nn.Linear(256, 128)\n",
        "    self.fc3 = nn.Linear(128, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "      y = self.conv1(x)\n",
        "      y = functional.relu(y)\n",
        "      y = self.conv2(y)\n",
        "      y = functional.relu(y)\n",
        "      y = self.pool1(y)\n",
        "      y = self.conv3(x)\n",
        "      y = functional.relu(y)\n",
        "      y = self.conv4(y)\n",
        "      y = functional.relu(y)\n",
        "      y = self.pool2(y)\n",
        "      y = self.drop1(y)\n",
        "      y = self.conv5(x)\n",
        "      y = functional.relu(y)\n",
        "      y = self.conv6(y)\n",
        "      y = functional.relu(y)\n",
        "      y = self.pool3(y)\n",
        "      y = self.drop2(y)\n",
        "      y = torch.flatten(y, 1)\n",
        "      y = self.fc1(y)\n",
        "      y = functional.relu(y)\n",
        "      y = self.fc2(y)\n",
        "      y = functional.relu(y)\n",
        "      y = self.fc3(y)\n",
        "      return y"
      ],
      "metadata": {
        "id": "rpxyunMymbV_"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_net_5 = ConvolutionalNeuralNet5().to(device)\n",
        "print(conv_net_5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4A7Fu0xnKQJ",
        "outputId": "5c29d46e-af9a-4a33-a3e1-f7e8ed6c9a8e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ConvolutionalNeuralNet5(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(2, 2), stride=(2, 2))\n",
            "  (conv2): Conv2d(16, 16, kernel_size=(2, 2), stride=(2, 2))\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(3, 32, kernel_size=(2, 2), stride=(2, 2))\n",
            "  (conv4): Conv2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
            "  (drop1): Dropout(p=0.3, inplace=False)\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv5): Conv2d(3, 64, kernel_size=(2, 2), stride=(2, 2))\n",
            "  (conv6): Conv2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
            "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (drop2): Dropout(p=0.3, inplace=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(conv_net_5.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "GpjJGsVjnNJT"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = [num for num in range(40)]\n",
        "accuracy_list = []\n",
        "for epoch in num_epochs: \n",
        "    classified_right = 0.0\n",
        "    classified_total = 0.0\n",
        "    training_index = 0.0\n",
        "    loss_epoch = 0.0\n",
        "    accuracy_epoch = 0.0\n",
        "    loss_current = 0.0\n",
        "    for train_data in training_dataset:  \n",
        "        images, labels = train_data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device) \n",
        "        conv_net_5.zero_grad()  \n",
        "        output = conv_net_5(images)  \n",
        "        loss = loss_function(output, labels)  \n",
        "        loss.backward()  \n",
        "        optimizer.step()  \n",
        "        enum = enumerate(output)\n",
        "        for index, a in enum:\n",
        "          classified_total += 1.0\n",
        "          if torch.argmax(a) == labels[index]:\n",
        "              classified_right += 1.0\n",
        "        loss_item = loss.item()\n",
        "        loss_current += loss_item\n",
        "        training_index += 1.0\n",
        "    loss_epoch = loss_current / training_index\n",
        "    accuracy_epoch = classified_right / classified_total\n",
        "    print(\"Epoch \" + str(epoch) + \" Training Loss: \" + str(loss_epoch) + \",     Training Accuracy: \" + str(accuracy_epoch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCjC3qcxnP4x",
        "outputId": "b17db102-bd90-47de-ad12-79010267ca60"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Training Loss: 2.3016408742846126,     Training Accuracy: 0.11348\n",
            "Epoch 1 Training Loss: 2.295316848913422,     Training Accuracy: 0.1406\n",
            "Epoch 2 Training Loss: 2.261310745688046,     Training Accuracy: 0.17336\n",
            "Epoch 3 Training Loss: 2.1137592132439087,     Training Accuracy: 0.2296\n",
            "Epoch 4 Training Loss: 2.014413152356892,     Training Accuracy: 0.25768\n",
            "Epoch 5 Training Loss: 1.9688024717523618,     Training Accuracy: 0.27798\n",
            "Epoch 6 Training Loss: 1.897671230308845,     Training Accuracy: 0.30794\n",
            "Epoch 7 Training Loss: 1.785638676884839,     Training Accuracy: 0.3515\n",
            "Epoch 8 Training Loss: 1.6848861815984293,     Training Accuracy: 0.3929\n",
            "Epoch 9 Training Loss: 1.6120600581474012,     Training Accuracy: 0.41614\n",
            "Epoch 10 Training Loss: 1.5638711958590066,     Training Accuracy: 0.43358\n",
            "Epoch 11 Training Loss: 1.5260894941856793,     Training Accuracy: 0.44554\n",
            "Epoch 12 Training Loss: 1.4972815673674464,     Training Accuracy: 0.45914\n",
            "Epoch 13 Training Loss: 1.47704348509269,     Training Accuracy: 0.4652\n",
            "Epoch 14 Training Loss: 1.4568232532657321,     Training Accuracy: 0.47576\n",
            "Epoch 15 Training Loss: 1.4386540332718578,     Training Accuracy: 0.47818\n",
            "Epoch 16 Training Loss: 1.424898795002257,     Training Accuracy: 0.48912\n",
            "Epoch 17 Training Loss: 1.4063419171458924,     Training Accuracy: 0.49224\n",
            "Epoch 18 Training Loss: 1.3905454911386874,     Training Accuracy: 0.5015\n",
            "Epoch 19 Training Loss: 1.373151454550531,     Training Accuracy: 0.50866\n",
            "Epoch 20 Training Loss: 1.3618867049741623,     Training Accuracy: 0.51072\n",
            "Epoch 21 Training Loss: 1.3450953032049682,     Training Accuracy: 0.52058\n",
            "Epoch 22 Training Loss: 1.3283015678605765,     Training Accuracy: 0.527\n",
            "Epoch 23 Training Loss: 1.3160136098904378,     Training Accuracy: 0.52962\n",
            "Epoch 24 Training Loss: 1.2969381627066972,     Training Accuracy: 0.5353\n",
            "Epoch 25 Training Loss: 1.2829080262909764,     Training Accuracy: 0.54222\n",
            "Epoch 26 Training Loss: 1.2690741435798538,     Training Accuracy: 0.54884\n",
            "Epoch 27 Training Loss: 1.2554917785212816,     Training Accuracy: 0.54858\n",
            "Epoch 28 Training Loss: 1.2445434726717528,     Training Accuracy: 0.5538\n",
            "Epoch 29 Training Loss: 1.2312762878282602,     Training Accuracy: 0.56166\n",
            "Epoch 30 Training Loss: 1.2234463652076624,     Training Accuracy: 0.56506\n",
            "Epoch 31 Training Loss: 1.2104650995005732,     Training Accuracy: 0.56894\n",
            "Epoch 32 Training Loss: 1.199808595659178,     Training Accuracy: 0.57436\n",
            "Epoch 33 Training Loss: 1.1851835878913666,     Training Accuracy: 0.57764\n",
            "Epoch 34 Training Loss: 1.176439970807956,     Training Accuracy: 0.58108\n",
            "Epoch 35 Training Loss: 1.1634323127434383,     Training Accuracy: 0.58434\n",
            "Epoch 36 Training Loss: 1.152603000935996,     Training Accuracy: 0.59018\n",
            "Epoch 37 Training Loss: 1.1408073814476238,     Training Accuracy: 0.59176\n",
            "Epoch 38 Training Loss: 1.130986490136827,     Training Accuracy: 0.59688\n",
            "Epoch 39 Training Loss: 1.1235811447395998,     Training Accuracy: 0.59722\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_correct = 0.0\n",
        "test_total = 0.0\n",
        "with torch.no_grad():\n",
        "    for test_data in testing_dataset:\n",
        "        images, labels = test_data\n",
        "        images = images.to(device)  \n",
        "        labels = labels.to(device)\n",
        "        output = conv_net_5(images)\n",
        "        enum = enumerate(output)\n",
        "        for index, a in enum:\n",
        "          test_total += 1.0\n",
        "          if torch.argmax(a) == labels[index]:\n",
        "            test_correct += 1.0\n",
        "accuracy_epoch = test_correct / test_total\n",
        "print(\"Testing Loss: \" + str(loss_epoch) + \",     Testing Accuracy: \" + str(accuracy_epoch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkYpoDkRnSx5",
        "outputId": "17015964-1f19-49c5-8dde-e3dc7b34b15d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Loss: 1.1235811447395998,     Testing Accuracy: 0.5725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "f4Rn5bPV-Znb",
        "outputId": "2e9353ae-4056-4488-c0da-a1967dc0d93b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0h_rP0wtBb03"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}